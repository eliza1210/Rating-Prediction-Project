{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating Prediction Project - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "We have a client who has a website where people write different reviews for technical products. Now they are adding a new feature to their website i.e. The reviewer will have to add stars(rating) as well with the review. The rating is out 5 stars and it only has 5 options available 1 star, 2 stars, 3 stars, 4 stars, 5 stars. Now they want to predict ratings for the reviews which were written in the past and they don’t have a rating. So, we have to build an application which can predict the rating by seeing the review.\n",
    "\n",
    "#### Data Collection Phase\n",
    "\n",
    "You have to scrape at least 20000 rows of data. You can scrape more data as well, it’s up to you. more the data better the model\n",
    "\n",
    "In this section you need to scrape the reviews of different laptops, Phones, Headphones, smart watches, Professional Cameras, Printers, Monitors, Home theater, Router from different e-commerce websites.\n",
    "\n",
    "Basically, we need these columns-\n",
    "1) reviews of the product.\n",
    "\n",
    "2) rating of the product.\n",
    "\n",
    "You can fetch other data as well, if you think data can be useful or can help in the project. It completely depends on your imagination or assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the data from Flipkart and Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries\n",
    "\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Ratings and Reviews from Flipkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayuk\\AppData\\Local\\Temp\\ipykernel_35624\\162822972.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"chromedriver.exe\")\n"
     ]
    },
    {
     "ename": "SessionNotCreatedException",
     "evalue": "Message: session not created: This version of ChromeDriver only supports Chrome version 101\nCurrent browser version is 104.0.5112.80 with binary path C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00F8B8F3+2406643]\n\tOrdinal0 [0x00F1AF31+1945393]\n\tOrdinal0 [0x00E0C748+837448]\n\tOrdinal0 [0x00E2C8B3+968883]\n\tOrdinal0 [0x00E284BA+951482]\n\tOrdinal0 [0x00E25D71+941425]\n\tOrdinal0 [0x00E58EE0+1150688]\n\tOrdinal0 [0x00E58B3A+1149754]\n\tOrdinal0 [0x00E54096+1130646]\n\tOrdinal0 [0x00E2E636+976438]\n\tOrdinal0 [0x00E2F546+980294]\n\tGetHandleVerifier [0x011F9612+2498066]\n\tGetHandleVerifier [0x011EC920+2445600]\n\tGetHandleVerifier [0x01024F2A+579370]\n\tGetHandleVerifier [0x01023D36+574774]\n\tOrdinal0 [0x00F21C0B+1973259]\n\tOrdinal0 [0x00F26688+1992328]\n\tOrdinal0 [0x00F26775+1992565]\n\tOrdinal0 [0x00F2F8D1+2029777]\n\tBaseThreadInitThunk [0x75266739+25]\n\tRtlGetFullPathName_UEx [0x770F8FEF+1215]\n\tRtlGetFullPathName_UEx [0x770F8FBD+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m driver\u001b[38;5;241m=\u001b[39m\u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchromedriver.exe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n\u001b[0;32m      3\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:70\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service:\n\u001b[0;32m     68\u001b[0m     service \u001b[38;5;241m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mWebDriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mservice_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_capabilities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mservice_log_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:92\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     \u001b[43mRemoteWebDriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChromiumRemoteConnection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremote_server_addr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbrowser_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrowser_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvendor_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvendor_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ignore_proxy\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquit()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:275\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, command_executor, desired_capabilities, browser_profile, proxy, keep_alive, file_detector, options)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_authenticator_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_client()\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcapabilities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrowser_profile\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:365\u001b[0m, in \u001b[0;36mWebDriver.start_session\u001b[1;34m(self, capabilities, browser_profile)\u001b[0m\n\u001b[0;32m    363\u001b[0m w3c_caps \u001b[38;5;241m=\u001b[39m _make_w3c_caps(capabilities)\n\u001b[0;32m    364\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcapabilities\u001b[39m\u001b[38;5;124m\"\u001b[39m: w3c_caps}\n\u001b[1;32m--> 365\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNEW_SESSION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m    367\u001b[0m     response \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:430\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    428\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    432\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:247\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mSessionNotCreatedException\u001b[0m: Message: session not created: This version of ChromeDriver only supports Chrome version 101\nCurrent browser version is 104.0.5112.80 with binary path C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00F8B8F3+2406643]\n\tOrdinal0 [0x00F1AF31+1945393]\n\tOrdinal0 [0x00E0C748+837448]\n\tOrdinal0 [0x00E2C8B3+968883]\n\tOrdinal0 [0x00E284BA+951482]\n\tOrdinal0 [0x00E25D71+941425]\n\tOrdinal0 [0x00E58EE0+1150688]\n\tOrdinal0 [0x00E58B3A+1149754]\n\tOrdinal0 [0x00E54096+1130646]\n\tOrdinal0 [0x00E2E636+976438]\n\tOrdinal0 [0x00E2F546+980294]\n\tGetHandleVerifier [0x011F9612+2498066]\n\tGetHandleVerifier [0x011EC920+2445600]\n\tGetHandleVerifier [0x01024F2A+579370]\n\tGetHandleVerifier [0x01023D36+574774]\n\tOrdinal0 [0x00F21C0B+1973259]\n\tOrdinal0 [0x00F26688+1992328]\n\tOrdinal0 [0x00F26775+1992565]\n\tOrdinal0 [0x00F2F8D1+2029777]\n\tBaseThreadInitThunk [0x75266739+25]\n\tRtlGetFullPathName_UEx [0x770F8FEF+1215]\n\tRtlGetFullPathName_UEx [0x770F8FBD+1165]\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "driver.find_element_by_xpath(\"//div[@class='_2QfC02']/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srch_items = ['laptops', 'Phones','smart watches','Monitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "review_text = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap():    \n",
    "        for i in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\"):\n",
    "            review_text.append(i.text)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "            title.append(i.text)\n",
    "        for i in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']/../div\"):\n",
    "            ratings.append(i.text)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in srch_items:\n",
    "    \n",
    "    #Locating search bar\n",
    "    \n",
    "    srchBar = driver.find_element_by_xpath(\"//div[@class='_3OO5Xc']/input\")\n",
    "    srchBar.clear()\n",
    "    srchBar.send_keys(i)\n",
    "    \n",
    "    #clicking on search button\n",
    "    \n",
    "    driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "    time.sleep(3)\n",
    "    page = []\n",
    "    for i in driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\"):\n",
    "        page.append(i.get_attribute('href'))\n",
    "    for i in page[0:4]:\n",
    "        driver.get(i)\n",
    "        time.sleep(3)\n",
    "        items = driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\")\n",
    "        for i in items:\n",
    "            urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    for _ in range(2):\n",
    "        driver.execute_script(\"window.scrollBy(0,6000)\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        #clicking on all reviews\n",
    "    \n",
    "    try:\n",
    "        btn=driver.find_element_by_xpath(\"//div[@class='_2c2kV-']/following::a\")\n",
    "        lnk = btn.get_attribute('href')\n",
    "        driver.get(lnk)\n",
    "        time.sleep(1)\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "\n",
    "    scrap()        \n",
    "    try:\n",
    "        n_page=driver.find_elements_by_xpath(\"//nav[@class='yFHi8N']/a\")\n",
    "        np=[]\n",
    "        for i in n_page:\n",
    "            np.append(i.get_attribute('href'))\n",
    "        for i in np[0:18]:\n",
    "            driver.get(i)\n",
    "            time.sleep(1)\n",
    "            scrap()\n",
    "    except: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratings), len(review_text), len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "\n",
    "data = list(zip(title,review_text,ratings))\n",
    "df2 = pd.DataFrame(data, columns = [\"Review_Title\",\"Reiew_Text\",\"Ratings\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the data into .csv file\n",
    "\n",
    "df2.to_csv(\"flipkrt_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Ratings and Reviews from Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.amazon.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srch_items = ['laptops','phones','headphones','smart watches', 'Professional Cameras', 'Printers', 'Monitors', 'Home theater', 'Router']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "review_text = []\n",
    "ratings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in srch_items:\n",
    "    srchbar = driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "    srchbar.send_keys(i)\n",
    "    driver.find_element_by_id(\"nav-search-submit-button\").click()  #clicking on search button\n",
    "    time.sleep(1)\n",
    "    item_url = []\n",
    "    for i in driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\"):\n",
    "        item_url.append(i.get_attribute('href'))\n",
    "    for i in item_url:\n",
    "        driver.get(i)\n",
    "        time.sleep(1)\n",
    "        for _ in range(2):\n",
    "            driver.execute_script(\"window.scrollBy(0,6000)\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "        #clicking on all reviews\n",
    "        \n",
    "        try:\n",
    "            driver.find_element_by_xpath(\"//a[@class='a-link-emphasis a-text-bold']\").click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        url_ = []\n",
    "        try:\n",
    "            two_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[4]/td[2]/a\")\n",
    "            url_.append(two_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            three_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[3]/td[2]/a\")\n",
    "            url_.append(three_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            one_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[5]/td[2]/a\")\n",
    "            url_.append(one_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            fiv_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[1]/td[2]/a\")\n",
    "            url_.append(fiv_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        try:\n",
    "            four_str = driver.find_element_by_xpath(\"//table[@id='histogramTable']/tbody/tr[2]/td[2]/a\")\n",
    "            url_.append(four_str.get_attribute('href'))\n",
    "        except: pass\n",
    "        \n",
    "        for i in url_:\n",
    "            driver.get(i)\n",
    "            time.sleep(1)\n",
    "            for i in range(10):\n",
    "                ids = driver.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none review-views celwidget']/div\")\n",
    "                comment_ids = []\n",
    "                for i in ids:\n",
    "                    comment_ids.append(i.get_attribute('id'))\n",
    "\n",
    "                for x in comment_ids:\n",
    "                    \n",
    "                    #Extracting user ids on page\n",
    "                    \n",
    "                    try:\n",
    "                        review_title = driver.find_element_by_xpath('//*[@id=\"' + x +'\"]/div/div/div[2]/a[2]/span[1]')\n",
    "                        title.append(review_title.get_attribute(\"innerHTML\"))\n",
    "                    except NoSuchElementException:\n",
    "                        title.append('')\n",
    "\n",
    "                    try:\n",
    "                        rating = driver.find_element_by_xpath('//*[@id=\"' + x +'\"]/div/div/div[2]/a[1]/i/span[1]')\n",
    "                        ratings.append(rating.get_attribute(\"innerHTML\"))\n",
    "                    except NoSuchElementException:\n",
    "                        ratings.append('')\n",
    "\n",
    "                    try:\n",
    "                        text = driver.find_element_by_xpath('//*[@id=\"' + x +'\"]/div/div/div[4]/span/span')\n",
    "                        review_text.append(text.get_attribute(\"innerHTML\"))\n",
    "                    except NoSuchElementException:\n",
    "                        review_text.append('')\n",
    "                try:\n",
    "                    driver.find_element_by_xpath(\"//ul[@class='a-pagination']/li[2]/a\").click()\n",
    "                    time.sleep(3)\n",
    "                except : break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratings), len(title), len(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataframe\n",
    "\n",
    "data = list(zip(title,review_text,ratings))\n",
    "df = pd.DataFrame(data, columns = [\"Review_title\",\"Reiew_text\",\"Ratings\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving into csv file\n",
    "\n",
    "df.to_csv(\"amazon_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the flipkart reviews file\n",
    "\n",
    "flpkrt = pd.read_csv(\"flipkrt_reviews.csv\")\n",
    "flpkrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the amazon reviews file\n",
    "\n",
    "df1 = pd.read_csv(\"amazon_reviews.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the Column Names to same Names in both files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the column name in amazon file similar to flipkart file\n",
    "\n",
    "df1.rename(columns = {'Review_title':'Review_Title'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the column name in amazon file similar to flipkart file\n",
    "\n",
    "df1.rename(columns = {'Reiew_text':'Review_Text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the column name in flipkart file\n",
    "\n",
    "flpkrt.rename(columns = {'Reiew_Text':'Review_Text'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unnamed: 0 in flipkart file\n",
    "\n",
    "flpkrt.drop(columns = 'Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unnamed: 0 in amazon file\n",
    "\n",
    "df1.drop(columns = 'Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concating both files\n",
    "\n",
    "Ratings_Prediction = pd.concat([df1, flpkrt],ignore_index=True)\n",
    "Ratings_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings_Prediction.to_csv(\"Ratings_Prediction_Scrapped_Data_File.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
